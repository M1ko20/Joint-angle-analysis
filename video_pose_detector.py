"""
Video re≈æim pro pose detection s trackingem a optimalizacemi
Roz≈°√≠≈ôen√≠ PoseDetector pro video streaming s lep≈°√≠m vyu≈æit√≠m tempor√°ln√≠ch informac√≠
"""

import cv2
import numpy as np
from pose_detector import PoseDetector


class VideoPoseDetector(PoseDetector):
    """
    Roz≈°√≠≈ôen√Ω detektor pro video re≈æim s podporou:
    - Tracking mezi framy
    - Tempor√°ln√≠ filtrov√°n√≠ (smooth)
    - Video-optimalizovan√© konfigurace
    """
    
    def __init__(self, detector_type="mediapipe", smooth_factor=0.5, confidence_threshold=0.5):
        """
        Args:
            detector_type: Typ detektoru (mediapipe, movenet, yolo, atd.)
            smooth_factor: Faktor pro tempor√°ln√≠ vyhlazov√°n√≠ (0-1, 0=vypnuto)
            confidence_threshold: Minim√°ln√≠ confidence pro detekci (0-1)
        """
        self.smooth_factor = smooth_factor
        self.prev_keypoints = None
        self.frame_count = 0
        self.video_confidence_threshold = confidence_threshold
        
        # Vol√°n√≠ parent konstruktoru
        super().__init__(detector_type)
        
        # Reinicializace s video-specifick√Ωmi parametry
        self._initialize_video_mode()
    
    def _initialize_video_mode(self):
        """P≈ôenastav√≠ detektory pro video re≈æim"""
        if self.detector_type == "mediapipe":
            self._init_mediapipe_video()
        elif self.detector_type in ["movenet", "movenet_lightning", "movenet_thunder"]:
            # MoveNet u≈æ m√° tracking zabudovan√Ω, ≈æ√°dn√° zmƒõna nen√≠ pot≈ôeba
            pass
        # OpenPose, ViTPose a YOLO nemaj√≠ speci√°ln√≠ video re≈æim
    
    def _init_mediapipe_video(self):
        """Reinicializuje MediaPipe pro video re≈æim"""
        try:
            import mediapipe as mp
            self.mp_pose = mp.solutions.pose
            self.mp_drawing = mp.solutions.drawing_utils
            self.mp_drawing_styles = mp.solutions.drawing_styles
            
            # VIDEO MODE - static_image_mode=False pro tracking
            # Pou≈æij confidence z UI
            conf = self.video_confidence_threshold
            self.detector = self.mp_pose.Pose(
                static_image_mode=False,  # ‚Üê KL√çƒåOV√â pro video!
                model_complexity=2,
                enable_segmentation=False,
                smooth_landmarks=True,     # ‚Üê Vyhlazov√°n√≠ pro video
                min_detection_confidence=conf,
                min_tracking_confidence=conf
            )
            print(f"‚úì MediaPipe - Video re≈æim aktivov√°n (tracking + smoothing, confidence={conf})")
        except Exception as e:
            print(f"‚ö†Ô∏è  MediaPipe video re≈æim selhal: {e}")
    
    def detect_pose(self, frame):
        """
        Detekuje pose s video optimalizacemi
        Returns: (keypoints, detection_result)
        """
        self.frame_count += 1
        
        # Detekce
        if self.detector_type == "mediapipe":
            keypoints, result = self._detect_mediapipe_video(frame)
        else:
            # Pro ostatn√≠ pou≈æij standardn√≠ detekci
            keypoints, result = super().detect_pose(frame)
        
        # Tempor√°ln√≠ vyhlazov√°n√≠ (smoothing)
        if keypoints is not None and self.smooth_factor > 0:
            keypoints = self._smooth_keypoints(keypoints)
        
        self.prev_keypoints = keypoints
        return keypoints, result
    
    def _detect_mediapipe_video(self, frame):
        """MediaPipe video detection - pou≈æ√≠v√° tracking"""
        # MediaPipe s static_image_mode=False u≈æ m√° tracking zabudovan√Ω
        return super()._detect_mediapipe(frame)
    
    def _smooth_keypoints(self, keypoints):
        """
        Tempor√°ln√≠ vyhlazov√°n√≠ keypoints pomoc√≠ exponenci√°ln√≠ho pr≈Ømƒõru
        Args:
            keypoints: Aktu√°ln√≠ keypoints
        Returns:
            Vyhlazen√© keypoints
        """
        if self.prev_keypoints is None:
            return keypoints
        
        if keypoints is None:
            return self.prev_keypoints
        
        # P≈ôevod na numpy array
        if isinstance(keypoints, list):
            keypoints = np.array(keypoints)
        if isinstance(self.prev_keypoints, list):
            prev = np.array(self.prev_keypoints)
        else:
            prev = self.prev_keypoints
        
        # Ujisti se, ≈æe maj√≠ stejnou velikost
        if keypoints.shape != prev.shape:
            return keypoints
        
        # Exponenci√°ln√≠ moving average
        # smoothed = Œ± * current + (1-Œ±) * previous
        alpha = 1.0 - self.smooth_factor
        smoothed = alpha * keypoints + (1.0 - alpha) * prev
        
        # Zachovej confidence scores z aktu√°ln√≠ch keypoints
        if len(keypoints.shape) == 1:
            # Flat array [x,y,c, x,y,c, ...]
            for i in range(2, len(keypoints), 3):
                smoothed[i] = keypoints[i]  # Confidence
        elif len(keypoints.shape) == 2:
            # Array [[x,y,c], [x,y,c], ...]
            smoothed[:, 2] = keypoints[:, 2]  # Confidence column
        
        return smoothed
    
    def reset_tracking(self):
        """Resetuje tracking informace (p≈ôi zmƒõnƒõ videa nebo sc√©ny)"""
        self.prev_keypoints = None
        self.frame_count = 0
        
        # Reset crop region pro MoveNet
        if self.detector_type in ["movenet", "movenet_lightning", "movenet_thunder"]:
            self.crop_region = None
        
        print(f"‚úì {self.detector_type} - Tracking resetov√°n")
    
    def get_tracking_info(self):
        """Vr√°t√≠ informace o trackingu"""
        return {
            'frame_count': self.frame_count,
            'has_prev_keypoints': self.prev_keypoints is not None,
            'smooth_factor': self.smooth_factor
        }


def get_video_capable_detectors():
    """
    Vrac√≠ seznam detektor≈Ø s podporou video re≈æimu
    Returns:
        dict: {detector_name: capabilities}
    """
    from pose_detector import (MEDIAPIPE_AVAILABLE, MOVENET_AVAILABLE, 
                               YOLO_AVAILABLE, OPENPOSE_AVAILABLE, 
                               VITPOSE_AVAILABLE)
    
    detectors = {}
    
    if MEDIAPIPE_AVAILABLE:
        detectors['mediapipe'] = {
            'video_support': True,
            'tracking': True,
            'smoothing': True,
            'name': 'MediaPipe'
        }
    
    if MOVENET_AVAILABLE:
        detectors['movenet_lightning'] = {
            'video_support': True,
            'tracking': True,
            'smoothing': True,
            'name': 'MoveNet Lightning'
        }
        detectors['movenet_thunder'] = {
            'video_support': True,
            'tracking': True,
            'smoothing': True,
            'name': 'MoveNet Thunder'
        }
    
    if YOLO_AVAILABLE:
        detectors['yolo11n'] = {
            'video_support': False,  # YOLO nem√° speci√°ln√≠ video re≈æim
            'tracking': False,
            'smoothing': False,
            'name': 'YOLO11n'
        }
        detectors['yolo11x'] = {
            'video_support': False,  # YOLO nem√° speci√°ln√≠ video re≈æim
            'tracking': False,
            'smoothing': False,
            'name': 'YOLO11x'
        }
    
    if OPENPOSE_AVAILABLE:
        detectors['openpose'] = {
            'video_support': False,  # OpenPose nem√° speci√°ln√≠ video re≈æim
            'tracking': False,
            'smoothing': False,
            'name': 'OpenPose'
        }
    
    if VITPOSE_AVAILABLE:
        detectors['vitpose'] = {
            'video_support': False,  # ViTPose nem√° speci√°ln√≠ video re≈æim
            'tracking': False,
            'smoothing': False,
            'name': 'ViTPose'
        }
    
    return detectors


if __name__ == "__main__":
    # Test video re≈æimu
    print("üé• Testov√°n√≠ video re≈æimu detektor≈Ø...")
    
    capable = get_video_capable_detectors()
    
    print("\n‚úÖ Detektory s video podporou:")
    for name, caps in capable.items():
        if caps['video_support']:
            features = []
            if caps['tracking']:
                features.append("tracking")
            if caps['smoothing']:
                features.append("smoothing")
            print(f"  ‚Ä¢ {caps['name']}: {', '.join(features)}")
    
    print("\n‚ùå Detektory pouze pro obr√°zky:")
    for name, caps in capable.items():
        if not caps['video_support']:
            print(f"  ‚Ä¢ {caps['name']}")
